{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM('vertexai/gemini-1.5-flash', \n",
    "          api_key=\"AIzaSyDZJa8zxCHIiLQdMi7kcX_cYhtM6Jw8Ai4\",\n",
    "          max_tokens = 1)\n",
    "\n",
    "# llm = LLM('vertexai/gemini-1.5-flash', \n",
    "#           api_key=\"YOUR_API_KEY\",\n",
    "#           temperature= ...,\n",
    "#           max_tokens= ...,\n",
    "#           top_p= ...,\n",
    "#           frequency_penalty= ...,\n",
    "#           presence_penalty= ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! What can I do for you today? \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.chat('Hello').chat_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='60db696f-9fe6-4c2a-83d7-6cffd342e55e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today? \\n', role='assistant', function_call=None, tool_calls=None))], created=1721914783, model='gemini-1.5-flash', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Hello', chat_output='Hello! How can I help you today? \\n', context=[{'role': 'user', 'content': 'Hello'}], provider='vertexai', deployment='gemini-1.5-flash', timestamp=1721914783.733218, parameters={'top_p': None, 'top_k': None, 'temperature': None, 'max_output_tokens': 1.0, 'frequency_penalty': None, 'presence_penalty': None}, metrics={'input_tokens': 1, 'output_tokens': 10, 'total_tokens': 11, 'cost_usd': 1.085e-05, 'latency_s': 1.429499864578247, 'time_to_first_token_s': 1.392812967300415, 'inter_token_latency_s': 0.01470947265625, 'tokens_per_second': 2.098636085485119})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.chat('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM('ollama/llama3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = llm.chat('hello')\n",
    "r.chat_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM('azure/bananas',\n",
    "          api_key = \"a42e89a4960343c28fb7b33ecf8ff88b\",\n",
    "          api_endpoint= \"https://daaistudio7873363449.openai.azure.com/openai/deployments/gpt-35-turbo/chat/completions?api-version=2023-03-15-preview\",\n",
    "          api_version= \"2024-02-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='e3eff357-a26d-43ae-b486-ef35f0bd2fc1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1721917908, model='gpt-35-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Hello', chat_output='Hello! How can I assist you today?', context=[{'role': 'user', 'content': 'Hello'}], provider='azure', deployment='bananas', timestamp=1721917908.586669, parameters={'temperature': None, 'max_tokens': None, 'top_p': None, 'frequency_penalty': None, 'presence_penalty': None}, metrics={'input_tokens': 1, 'output_tokens': 9, 'total_tokens': 10, 'cost_usd': 0.00114, 'latency_s': 0.5796680450439453, 'time_to_first_token_s': 0.4684178829193115, 'inter_token_latency_s': 0.004330461675470526, 'tokens_per_second': 20.701503390773016})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.chat(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM('azure/da-Mistral-small',\n",
    "          api_key = \"jKG4E2bspjKTXyuv8QIKMUkK5oSaiOvD\",\n",
    "          api_endpoint= \"https://da-Mistral-small.swedencentral.models.ai.azure.com\",\n",
    "          api_version= \"2024-02-01\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmstudiodev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
