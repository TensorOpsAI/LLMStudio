{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to LLMstudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import clients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LLMstudio Engine on http://localhost:50001 \n",
      "Running LLMstudio Tracking on http://localhost:50002 \n"
     ]
    }
   ],
   "source": [
    "from llmstudio import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set OPENAI_API_KEY and ANTHROPIC_API_KEY on .env file\n",
    "\n",
    "claude2 = LLM(\"anthropic/claude-2.1\") # or you can pass api_key as an argument here\n",
    "gpt4 = LLM(\"openai/gpt-4\")\n",
    "gpt3 = LLM(\"openai/gpt-3.5-turbo\")\n",
    "gemini = LLM(\"vertexai/gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (non-stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='f165c819-fe3f-4c42-bc6c-a95d104d81ac', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an artificial intelligence, I don't have a personal name. I'm known as OpenAI.\", role='assistant', function_call=None, tool_calls=None))], created=1726331551, model='gpt-4', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your name\", chat_output=\"As an artificial intelligence, I don't have a personal name. I'm known as OpenAI.\", context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4-0613', timestamp=1726331552.8207412, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 4, 'output_tokens': 20, 'total_tokens': 24, 'cost_usd': 0.0013200000000000002, 'latency_s': 1.5932490825653076, 'time_to_first_token_s': 0.8199670314788818, 'inter_token_latency_s': 0.03650605110895066, 'tokens_per_second': 13.808261520902658})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4.chat(\"What's your name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='272266c3-c569-4f63-ac62-dc37d93c7348', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As an Artificial intelligence, I don't have a personal name, you can simply address me as AI or OpenAI.\", role='assistant', function_call=None, tool_calls=None))], created=1726331556, model='gpt-4', object='chat.completion', service_tier=None, system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your name\", chat_output=\"As an Artificial intelligence, I don't have a personal name, you can simply address me as AI or OpenAI.\", context=[{'role': 'user', 'content': \"What's your name\"}], provider='openai', deployment='gpt-4-0613', timestamp=1726331557.884067, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 4, 'output_tokens': 24, 'total_tokens': 28, 'cost_usd': 0.0015600000000000002, 'latency_s': 1.9345951080322266, 'time_to_first_token_s': 1.025731086730957, 'inter_token_latency_s': 0.0363308048248291, 'tokens_per_second': 13.439504675707518})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await gpt4.async_chat(\"What's your name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat (stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space is a vast and mysterious expanse that has fascinated humanity for centuries. It is an endless void filled with stars, planets, galaxies, and other celestial bodies. The exploration of space has led to countless discoveries and advancements in science and technology. From the first moon landing to the study of black holes and distant galaxies, space continues to captivate the imagination and inspire wonder. It serves as a reminder of the infinite possibilities that exist beyond our own planet and the potential for new frontiers to be explored. As our understanding of space continues to grow, so does our desire to unravel its mysteries and unlock the secrets of the universe."
     ]
    }
   ],
   "source": [
    "response = gpt3.chat(\"Write a paragfraph about space\", is_stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! How are you doing today?"
     ]
    }
   ],
   "source": [
    "async for chunk in await gpt3.async_chat(\"Say hi back\", is_stream=True):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmstudio import LLM\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3 = LLM('openai/gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletion(id='bce77107-790e-4194-b709-c1f973908e13', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am a virtual assistant and I do not have a personal name. You can simply refer to me as \"assistant\". How can I assist you today?', role='assistant', function_call=None, tool_calls=None))], created=1718357127, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's your name?\", chat_output='I am a virtual assistant and I do not have a personal name. You can simply refer to me as \"assistant\". How can I assist you today?', context=[{'role': 'user', 'content': \"What's your name?\"}], provider='openai', timestamp=1718357130.3642838, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 31, 'total_tokens': 36, 'cost_usd': 4.9e-05, 'latency_s': 2.8777408599853516, 'time_to_first_token_s': 2.8716890811920166, 'inter_token_latency_s': 8.686631917953491e-05, 'tokens_per_second': 11.46732857668358}),\n",
       " ChatCompletion(id='f5058611-d4e5-48cc-810f-5cfbf82bd70f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", role='assistant', function_call=None, tool_calls=None))], created=1718357129, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me a joke.', chat_output=\"Why couldn't the bicycle find its way home? Because it lost its bearings!\", context=[{'role': 'user', 'content': 'Tell me a joke.'}], provider='openai', timestamp=1718357130.392538, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 16, 'total_tokens': 21, 'cost_usd': 2.65e-05, 'latency_s': 0.9708259105682373, 'time_to_first_token_s': 0.9693810939788818, 'inter_token_latency_s': 7.653236389160156e-05, 'tokens_per_second': 18.540914291692484}),\n",
       " ChatCompletion(id='bb195dce-30b4-4836-a9bc-9d73ea81efcc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm sorry, I am an AI and do not have the ability to determine the current weather. You can check the weather in your area by using a weather app on your phone or by visiting a weather website.\", role='assistant', function_call=None, tool_calls=None))], created=1718357129, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input=\"What's the weather like?\", chat_output=\"I'm sorry, I am an AI and do not have the ability to determine the current weather. You can check the weather in your area by using a weather app on your phone or by visiting a weather website.\", context=[{'role': 'user', 'content': \"What's the weather like?\"}], provider='openai', timestamp=1718357130.386699, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 43, 'total_tokens': 49, 'cost_usd': 6.75e-05, 'latency_s': 1.5981099605560303, 'time_to_first_token_s': 1.594458818435669, 'inter_token_latency_s': 7.893822409889914e-05, 'tokens_per_second': 28.158262641916803}),\n",
       " ChatCompletion(id='2e689f44-7977-4a21-9b45-4ac9fcf17e0e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"I'm an AI assistant, so I don't have a physical voice to sing with. However, I can provide lyrics or information about songs if you'd like! Just let me know how I can assist you.\", role='assistant', function_call=None, tool_calls=None))], created=1718357128, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Can you sing a song?', chat_output=\"I'm an AI assistant, so I don't have a physical voice to sing with. However, I can provide lyrics or information about songs if you'd like! Just let me know how I can assist you.\", context=[{'role': 'user', 'content': 'Can you sing a song?'}], provider='openai', timestamp=1718357130.378707, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 6, 'output_tokens': 43, 'total_tokens': 49, 'cost_usd': 6.75e-05, 'latency_s': 2.229912042617798, 'time_to_first_token_s': 2.22599196434021, 'inter_token_latency_s': 8.436224677345969e-05, 'tokens_per_second': 20.180168159086847}),\n",
       " ChatCompletion(id='257fb034-90c5-4d98-8ff7-1830ff3a0954', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I am an AI assistant designed to provide information and assistance in various topics. I am constantly learning and improving my abilities to help users with their queries and tasks. I am programmed to provide accurate and reliable information based on the data available to me. If you have any specific questions or need assistance, feel free to ask!', role='assistant', function_call=None, tool_calls=None))], created=1718357130, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='Tell me about yourself.', chat_output='I am an AI assistant designed to provide information and assistance in various topics. I am constantly learning and improving my abilities to help users with their queries and tasks. I am programmed to provide accurate and reliable information based on the data available to me. If you have any specific questions or need assistance, feel free to ask!', context=[{'role': 'user', 'content': 'Tell me about yourself.'}], provider='openai', timestamp=1718357132.529829, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 5, 'output_tokens': 64, 'total_tokens': 69, 'cost_usd': 9.850000000000001e-05, 'latency_s': 2.184094190597534, 'time_to_first_token_s': 0.6790041923522949, 'inter_token_latency_s': 0.023148767764751728, 'tokens_per_second': 30.21847697051171}),\n",
       " ChatCompletion(id='813d3a00-2765-479c-b158-bbf916232706', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"De sun be shinin' bright and de breeze be cool, perfect weather for jammin' on de beach! How 'bout you, how's de weather by you?\", role='assistant', function_call=None, tool_calls=None))], created=1718357131, model='gpt-3.5-turbo', object='chat.completion', system_fingerprint=None, usage=None, session_id=None, chat_input='How is the weather today?', chat_output=\"De sun be shinin' bright and de breeze be cool, perfect weather for jammin' on de beach! How 'bout you, how's de weather by you?\", context=[{'role': 'system', 'content': 'You are a tchill dude from jamaica'}, {'role': 'user', 'content': 'Hello, how are you?'}, {'role': 'assistant', 'content': 'Ye man doin fain man!'}, {'role': 'user', 'content': 'How is the weather today?'}], provider='openai', timestamp=1718357132.537878, parameters={'temperature': 1, 'max_tokens': 2048, 'top_p': 1, 'frequency_penalty': 0, 'presence_penalty': 0}, metrics={'input_tokens': 31, 'output_tokens': 35, 'total_tokens': 66, 'cost_usd': 6.8e-05, 'latency_s': 1.5229389667510986, 'time_to_first_token_s': 1.5202741622924805, 'inter_token_latency_s': 6.913476520114475e-05, 'tokens_per_second': 24.29512988227787})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_prompt= [{\"role\": \"system\", \"content\": \"You are a tchill dude from jamaica\"},\n",
    "          {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n",
    "          {\"role\": \"assistant\", \"content\": \"Ye man doin fain man!\"},\n",
    "          {\"role\": \"user\", \"content\": \"How is the weather today?\"}]\n",
    "\n",
    "inputs = [\n",
    "    \"What's your name?\",\n",
    "    \"Tell me a joke.\",\n",
    "    \"What's the weather like?\",\n",
    "    \"Can you sing a song?\",\n",
    "    \"Tell me about yourself.\",\n",
    "    complex_prompt\n",
    "]\n",
    "\n",
    "responses = gpt3.run_batch_chat_coroutine(inputs)\n",
    "responses"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
